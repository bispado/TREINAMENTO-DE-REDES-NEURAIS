# üéì Checkpoint 02 - Redes Neurais com Keras + Vis√£o Computacional

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Keras](https://img.shields.io/badge/Keras-TensorFlow-red)
![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-00D4FF)
![MediaPipe](https://img.shields.io/badge/MediaPipe-Google-FF6F00)

**Curso:** Intelig√™ncia Artificial  
**Professor:** Andr√© Tritiack  
**Institui√ß√£o:** FIAP  
**Data:** Outubro 2025

---

## üë• Integrantes do Grupo

- **Vinicius Murtinho Vicente** - RM551151
- **Lucas Barreto Consentino** - RM557107  
- **Gustavo Bispo Cordeiro** - RM558515

---

## üìã Sum√°rio

- [Objetivo do Projeto](#-objetivo-do-projeto)
- [Parte 01 - Redes Neurais com Keras (40%)](#-parte-01---redes-neurais-com-keras-40)
- [Parte 02 - Vis√£o Computacional (60%)](#-parte-02---vis√£o-computacional-60)
- [Ferramentas Utilizadas](#Ô∏è-ferramentas-utilizadas)
- [Datasets](#-datasets)
- [Hiperpar√¢metros e Configura√ß√µes](#Ô∏è-hiperpar√¢metros-e-configura√ß√µes)
- [Comparativo entre Abordagens](#-comparativo-entre-abordagens)
- [Resultados e Observa√ß√µes](#-resultados-e-observa√ß√µes)
- [Como Executar](#-como-executar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [V√≠deo de Demonstra√ß√£o](#-v√≠deo-de-demonstra√ß√£o)
- [Refer√™ncias](#-refer√™ncias)

---

## üéØ Objetivo do Projeto

Este projeto do **Checkpoint 02** tem como objetivo principal implementar e comparar diferentes t√©cnicas de Machine Learning e Deep Learning em dois contextos distintos:

### **Parte 01 (40%):** Redes Neurais para Dados Tabulares
Desenvolver e comparar redes neurais em Keras com modelos tradicionais do scikit-learn em problemas de:
- **Classifica√ß√£o Multiclasse** (Wine Dataset)
- **Regress√£o** (California Housing Dataset)

### **Parte 02 (60%):** Vis√£o Computacional
Treinar e demonstrar um modelo de Vis√£o Computacional utilizando **duas ferramentas diferentes**:
- **YOLOv8** - Detec√ß√£o de objetos com Deep Learning
- **MediaPipe** - Reconhecimento de gestos em tempo real

**Objetivo Pr√°tico:** Comparar t√©cnicas de detec√ß√£o, classifica√ß√£o e rastreamento de gestos de m√£o para o jogo "Pedra, Papel e Tesoura" (Rock, Paper, Scissors).

---

## üìä Parte 01 - Redes Neurais com Keras (40%)

Esta se√ß√£o implementa redes neurais em Keras para problemas de classifica√ß√£o e regress√£o com dados tabulares, comparando-as com modelos tradicionais do scikit-learn.

### üî∑ Exerc√≠cio 1 - Classifica√ß√£o Multiclasse

#### Dataset: Wine Dataset (UCI)
- **Descri√ß√£o:** Dataset com 178 amostras de vinhos de 3 classes diferentes
- **Features:** 13 atributos qu√≠micos (√°lcool, acidez m√°lica, cinzas, alcalinidade, magn√©sio, fen√≥is, flavonoides, etc.)
- **Classes:** 3 tipos de vinho (classe 0, 1, 2)
- **Fonte:** UCI Machine Learning Repository

#### Arquitetura da Rede Neural:
```python
- Camada de Entrada: 13 features
- Camada Oculta 1: 32 neur√¥nios + ReLU
- Camada Oculta 2: 32 neur√¥nios + ReLU
- Camada de Sa√≠da: 3 neur√¥nios + Softmax
- Loss: categorical_crossentropy
- Optimizer: Adam
- Epochs: 100
```

#### Modelos Comparados:
1. **Rede Neural (Keras)** - configura√ß√£o acima
2. **Random Forest Classifier** - 100 estimadores
3. **Logistic Regression** - multi_class='multinomial'

#### Resultados:

| Modelo | Acur√°cia | Observa√ß√µes |
|--------|----------|-------------|
| **Random Forest** | **100.00%** | ‚úÖ Melhor desempenho |
| Logistic Regression | 97.22% | ‚úÖ Excelente resultado |
| Keras Neural Network | 91.67% | ‚úÖ Bom desempenho |

**An√°lise:**
- O Random Forest alcan√ßou 100% de acur√°cia, classificando perfeitamente as 3 classes
- A Logistic Regression obteve 97.22%, resultado excelente para um modelo linear
- A Rede Neural Keras atingiu 91.67%, competitivo considerando o tamanho reduzido do dataset
- Para datasets pequenos e bem estruturados, modelos ensemble tendem a superar redes neurais profundas

**Conclus√£o:** O dataset Wine possui boa separabilidade entre classes, permitindo que modelos tradicionais obtenham resultados excelentes.

---

### üî∑ Exerc√≠cio 2 - Regress√£o

#### Dataset: California Housing Dataset
- **Descri√ß√£o:** Dataset com 20.640 amostras de pre√ßos de im√≥veis na Calif√≥rnia
- **Features:** 8 atributos (MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude)
- **Target:** Valor m√©dio das casas (em $100.000)
- **Fonte:** Scikit-learn

#### Arquitetura da Rede Neural:
```python
- Camada de Entrada: 8 features
- Camada Oculta 1: 64 neur√¥nios + ReLU
- Camada Oculta 2: 32 neur√¥nios + ReLU
- Camada Oculta 3: 16 neur√¥nios + ReLU
- Camada de Sa√≠da: 1 neur√¥nio + Linear
- Loss: mse (Mean Squared Error)
- Optimizer: Adam
- Epochs: 100
```

#### Modelos Comparados:
1. **Rede Neural (Keras)** - configura√ß√£o acima
2. **Random Forest Regressor** - 100 estimadores
3. **Linear Regression** - baseline

#### Resultados:

| Modelo | RMSE | MAE | R¬≤ | Observa√ß√µes |
|--------|------|-----|-----|-------------|
| **Random Forest** | **0.5051** | **0.3274** | **0.8053** | ‚úÖ Melhor desempenho |
| Keras Neural Network | 0.5354 | 0.3578 | 0.7812 | ‚úÖ Muito competitivo |
| Linear Regression | 0.7456 | 0.5332 | 0.5758 | ‚ö†Ô∏è Baseline |

**An√°lise:**
- O Random Forest obteve o melhor resultado com RMSE de 0.5051 e R¬≤ de 0.8053
- A Rede Neural Keras ficou muito pr√≥xima com RMSE de 0.5354 e R¬≤ de 0.7812
- A Regress√£o Linear teve desempenho inferior (R¬≤ = 0.5758), indicando rela√ß√µes n√£o-lineares nos dados
- **Feature mais importante (Random Forest):** MedInc (renda m√©dia) com 52.49% de import√¢ncia

**Conclus√£o:** Para problemas de regress√£o com datasets maiores, tanto Random Forest quanto Redes Neurais demonstram excelente capacidade de capturar padr√µes complexos.

---

### üìù Escolha dos Hiperpar√¢metros - Parte 01

#### Exerc√≠cio 1 (Classifica√ß√£o):
- **2 camadas ocultas com 32 neur√¥nios cada**: Balanceia complexidade e capacidade de generaliza√ß√£o para o dataset pequeno (178 amostras)
- **ReLU**: Fun√ß√£o de ativa√ß√£o eficiente que evita vanishing gradient
- **Softmax**: Ideal para classifica√ß√£o multiclasse, produz distribui√ß√£o de probabilidades
- **Categorical Crossentropy**: Loss padr√£o para classifica√ß√£o multiclasse
- **Adam**: Optimizer adaptativo que converge rapidamente

#### Exerc√≠cio 2 (Regress√£o):
- **3 camadas ocultas (64‚Üí32‚Üí16)**: Arquitetura progressivamente menor permite extra√ß√£o hier√°rquica de features
- **ReLU**: Ativa√ß√£o eficiente para camadas ocultas
- **Linear**: Ativa√ß√£o na sa√≠da permite predizer valores cont√≠nuos sem limita√ß√£o
- **MSE**: Loss padr√£o para regress√£o, penaliza erros grandes
- **Adam**: Optimizer robusto que ajusta learning rate automaticamente

---

## üéÆ Parte 02 - Vis√£o Computacional (60%)

Esta se√ß√£o implementa e compara duas abordagens distintas de Vis√£o Computacional para detec√ß√£o e classifica√ß√£o de gestos de m√£o em tempo real no jogo "Pedra, Papel e Tesoura".

### Objetivos Espec√≠ficos:

1. ‚úÖ Treinar um modelo **YOLOv8** do zero utilizando dataset customizado
2. ‚úÖ Implementar detec√ß√£o em tempo real com **MediaPipe** usando an√°lise geom√©trica
3. ‚úÖ Comparar as duas abordagens em termos de precis√£o, velocidade e recursos
4. ‚úÖ Desenvolver aplica√ß√µes pr√°ticas execut√°veis em tempo real via webcam
5. ‚úÖ Documentar todo o processo incluindo desafios e solu√ß√µes

---

## üõ†Ô∏è Ferramentas Utilizadas

### **Parte 01 - Redes Neurais:**

#### 1Ô∏è‚É£ Keras/TensorFlow
- **Tipo:** Framework de Deep Learning
- **Uso:** Constru√ß√£o e treinamento de redes neurais
- **Vers√£o:** Keras 2.x com backend TensorFlow 2.x

#### 2Ô∏è‚É£ Scikit-learn
- **Tipo:** Biblioteca de Machine Learning tradicional
- **Uso:** Modelos de compara√ß√£o (Random Forest, Logistic Regression, Linear Regression)
- **Vers√£o:** 1.3+

#### 3Ô∏è‚É£ Pandas, NumPy, Matplotlib, Seaborn
- **Uso:** Manipula√ß√£o de dados, an√°lise explorat√≥ria e visualiza√ß√£o

---

### **Parte 02 - Vis√£o Computacional:**

#### 1Ô∏è‚É£ YOLOv8 (You Only Look Once v8) ‚≠ê

**Tipo:** Detec√ß√£o de Objetos com Deep Learning

**Descri√ß√£o:**
- Framework de √∫ltima gera√ß√£o para detec√ß√£o de objetos em tempo real
- Utiliza redes neurais convolucionais (CNN) para detectar e classificar objetos
- Treinamento realizado com transfer learning a partir de pesos pr√©-treinados no COCO dataset
- Vers√£o utilizada: **YOLOv8n (Nano)** - otimizada para velocidade

**Principais Caracter√≠sticas:**
- ‚úÖ Alta precis√£o na detec√ß√£o de m√∫ltiplos objetos
- ‚úÖ Bounding boxes precisas ao redor dos objetos
- ‚úÖ Robusto a varia√ß√µes de ilumina√ß√£o, √¢ngulo e escala
- ‚úÖ Capacidade de detectar m√∫ltiplas m√£os simultaneamente
- ‚ö†Ô∏è Requer GPU para treinamento eficiente
- ‚ö†Ô∏è Necessita dataset anotado com bounding boxes

**Implementa√ß√£o:**
- Notebook Jupyter para treinamento no Google Colab
- Script Python para infer√™ncia em tempo real
- Framework: Ultralytics

---

#### 2Ô∏è‚É£ MediaPipe Hands ‚≠ê

**Tipo:** Detec√ß√£o de Landmarks com Machine Learning

**Descri√ß√£o:**
- Framework do Google para detec√ß√£o de m√£os e extra√ß√£o de pontos-chave (landmarks)
- Detecta 21 pontos em cada m√£o (articula√ß√µes e pontas dos dedos)
- Classifica√ß√£o baseada em l√≥gica geom√©trica dos landmarks
- Modelo pr√©-treinado, sem necessidade de treinamento adicional

**Principais Caracter√≠sticas:**
- ‚úÖ Leve e r√°pido (funciona em CPU)
- ‚úÖ N√£o requer dataset ou treinamento
- ‚úÖ Detecta landmarks precisos das m√£os
- ‚úÖ Ideal para rastreamento de gestos em tempo real
- ‚ö†Ô∏è Classifica√ß√£o baseada em regras (n√£o aprendizado profundo)
- ‚ö†Ô∏è Pode ter dificuldade com gestos amb√≠guos

**Implementa√ß√£o:**
- Script Python com l√≥gica de classifica√ß√£o customizada
- An√°lise geom√©trica dos dedos estendidos/dobrados
- Suaviza√ß√£o temporal das predi√ß√µes

---

#### 3Ô∏è‚É£ Ferramentas Auxiliares

- **OpenCV (cv2):** Captura e processamento de v√≠deo em tempo real
- **NumPy:** Opera√ß√µes matem√°ticas com arrays
- **Google Colab:** Ambiente para treinamento do YOLOv8 com GPU gratuita
- **Roboflow:** Gerenciamento e download do dataset

---

## üìä Datasets

### **Parte 01 - Dados Tabulares:**

#### üç∑ Wine Dataset (Exerc√≠cio 1)
- **Descri√ß√£o:** Classifica√ß√£o de vinhos italianos
- **Amostras:** 178
- **Features:** 13 (qu√≠micas)
- **Classes:** 3
- **Fonte:** UCI Machine Learning Repository
- **Formato:** CSV

#### üèòÔ∏è California Housing Dataset (Exerc√≠cio 2)
- **Descri√ß√£o:** Pre√ßos de im√≥veis na Calif√≥rnia
- **Amostras:** 20.640
- **Features:** 8 (demogr√°ficas e geogr√°ficas)
- **Target:** Pre√ßo m√©dio das casas
- **Fonte:** Scikit-learn (built-in)
- **Formato:** Numpy arrays

---

### **Parte 02 - Vis√£o Computacional:**

#### üéÆ Rock Paper Scissors Detection Dataset

**Informa√ß√µes Gerais:**
- **Nome:** Rock Paper Scissors Detection Dataset
- **Fonte:** [Roboflow Universe](https://universe.roboflow.com/bispado/rock-paper-scissors-sxsw-zbvgm)
- **Formato:** YOLOv8 (anota√ß√µes em .txt)
- **Total de Imagens:** 3.129
- **Classes:** 3 (Paper, Rock, Scissors)

**Distribui√ß√£o:**

| Conjunto   | Imagens | Porcentagem |
|------------|---------|-------------|
| Treino     | 2.196   | 70.2%       |
| Valida√ß√£o  | 604     | 19.3%       |
| Teste      | 329     | 10.5%       |

**Caracter√≠sticas:**
- ‚úÖ Imagens de alta qualidade com diversas condi√ß√µes
- ‚úÖ M√∫ltiplas pessoas e √¢ngulos de c√¢mera
- ‚úÖ Varia√ß√µes de ilumina√ß√£o e backgrounds
- ‚úÖ Anota√ß√µes precisas com bounding boxes
- ‚úÖ Balanceamento razo√°vel entre as classes

**Links:**
- üîó **Google Drive:** [Link para o dataset](https://drive.google.com/drive/folders/1Lyaf5Ns15ABItUMfwP8jumKftJxOSmjL?usp=sharing)
- üîó **Roboflow:** [Rock Paper Scissors Dataset](https://universe.roboflow.com/bispado/rock-paper-scissors-sxsw-zbvgm/dataset/1)

---

## ‚öôÔ∏è Hiperpar√¢metros e Configura√ß√µes

### **Parte 02 - Vis√£o Computacional:**

#### YOLOv8 - Configura√ß√µes de Treinamento

**Modelo Base:**
- **Arquitetura:** YOLOv8n (Nano)
- **Par√¢metros:** ~3.2M
- **Pesos Iniciais:** COCO pr√©-treinado (transfer learning)
- **Input Size:** 640x640 pixels

**Hiperpar√¢metros Principais:**

| Par√¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| `epochs` | 100 | Converg√™ncia completa com early stopping |
| `batch_size` | 16 | Otimizado para GPU T4 do Colab |
| `learning_rate_initial` | 0.01 | Taxa padr√£o do YOLO com bons resultados |
| `learning_rate_final` | 0.01 | Mant√©m aprendizado ao final |
| `momentum` | 0.937 | Momentum padr√£o do SGD |
| `weight_decay` | 0.0005 | Regulariza√ß√£o L2 para evitar overfitting |
| `warmup_epochs` | 3 | Aquecimento gradual do learning rate |
| `patience` | 50 | Early stopping ap√≥s 50 epochs sem melhora |
| `optimizer` | Auto (AdamW) | Escolha autom√°tica baseada no dataset |
| `image_size` | 640 | Resolu√ß√£o padr√£o do YOLO |
| `workers` | 8 | Paraleliza√ß√£o do data loading |
| `device` | cuda:0 | GPU para acelera√ß√£o |

**Data Augmentation:**
- ‚úÖ Mosaic Augmentation (primeiros 90 epochs)
- ‚úÖ Mixup
- ‚úÖ HSV Color Augmentation
- ‚úÖ Random Horizontal Flip
- ‚úÖ Scale & Translate

---

#### MediaPipe - Configura√ß√µes

**Par√¢metros do Modelo:**

| Par√¢metro | Valor | Justificativa |
|-----------|-------|---------------|
| `min_detection_confidence` | 0.7 | Detectar apenas m√£os com alta confian√ßa |
| `min_tracking_confidence` | 0.5 | Rastreamento mais permissivo para fluidez |
| `max_num_hands` | 2 | Detectar at√© 2 m√£os simultaneamente |
| `model_complexity` | 1 | Modelo full (n√£o lite) para melhor precis√£o |

**L√≥gica de Classifica√ß√£o Customizada:**

1. **Contagem de dedos estendidos:**
   - An√°lise das posi√ß√µes Y dos landmarks (pontos-chave)
   - Polegar: compara√ß√£o horizontal (X) considerando lateralidade da m√£o
   - Outros dedos: compara√ß√£o vertical (Y da ponta vs base)

2. **Regras de Classifica√ß√£o:**
   - **Rock (Pedra):** 0-1 dedos estendidos ‚Üí Confian√ßa 85-95%
   - **Paper (Papel):** 4-5 dedos estendidos ‚Üí Confian√ßa 85-95%
   - **Scissors (Tesoura):** 2-3 dedos (√≠ndice + m√©dio) ‚Üí Confian√ßa 70-90%

3. **Suaviza√ß√£o Temporal:**
   - Hist√≥rico de 5 frames
   - Predi√ß√£o final = moda (gesto mais frequente)
   - Evita oscila√ß√µes indesejadas

---

## üîÑ Comparativo entre Abordagens

### **Parte 01 - Redes Neurais vs Modelos Tradicionais:**

#### Classifica√ß√£o (Wine Dataset):

| Aspecto | Rede Neural (Keras) | Random Forest | Logistic Regression |
|---------|---------------------|---------------|---------------------|
| **Acur√°cia** | 91.67% | **100.00%** ‚úÖ | 97.22% |
| **Complexidade** | Alta (requer tuning) | M√©dia | Baixa |
| **Tempo de Treino** | ~10s | ~2s | <1s |
| **Interpretabilidade** | ‚ùå Baixa | ‚ö†Ô∏è M√©dia | ‚úÖ Alta |
| **Overfitting** | ‚ö†Ô∏è Risco m√©dio | ‚ö†Ô∏è Risco m√©dio | ‚úÖ Baixo risco |

**Conclus√£o:** Para datasets pequenos e estruturados, Random Forest supera redes neurais.

---

#### Regress√£o (California Housing):

| Aspecto | Rede Neural (Keras) | Random Forest | Linear Regression |
|---------|---------------------|---------------|-------------------|
| **RMSE** | 0.5354 | **0.5051** ‚úÖ | 0.7456 |
| **R¬≤** | 0.7812 | **0.8053** ‚úÖ | 0.5758 |
| **Complexidade** | Alta | M√©dia | Baixa |
| **Tempo de Treino** | ~45s | ~15s | <1s |
| **Capacidade N√£o-Linear** | ‚úÖ Alta | ‚úÖ Alta | ‚ùå Baixa |

**Conclus√£o:** Para datasets maiores, redes neurais se tornam competitivas, mas Random Forest ainda lidera.

---

### **Parte 02 - YOLOv8 vs MediaPipe:**

#### Tabela Comparativa Geral

| Crit√©rio | YOLOv8 | MediaPipe | Vencedor |
|----------|--------|-----------|----------|
| **Precis√£o/mAP** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (85-95%) | ‚≠ê‚≠ê‚≠ê‚≠ê (80-90%) | YOLOv8 |
| **Velocidade (FPS)** | ‚≠ê‚≠ê‚≠ê‚≠ê (30-60 com GPU) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (60-120 em CPU) | MediaPipe |
| **Uso de Recursos** | ‚≠ê‚≠ê‚≠ê (Requer GPU) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Funciona em CPU) | MediaPipe |
| **Facilidade de Implementa√ß√£o** | ‚≠ê‚≠ê‚≠ê (Requer treinamento) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Modelo pr√©-treinado) | MediaPipe |
| **Flexibilidade** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Qualquer objeto) | ‚≠ê‚≠ê‚≠ê (Apenas m√£os/corpo) | YOLOv8 |
| **Robustez** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Muito robusto) | ‚≠ê‚≠ê‚≠ê‚≠ê (Bom, mas sens√≠vel) | YOLOv8 |
| **Escalabilidade** | ‚≠ê‚≠ê‚≠ê‚≠ê (Escal√°vel com recursos) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Muito escal√°vel) | MediaPipe |

---

#### An√°lise Detalhada por Crit√©rio:

##### üéØ Precis√£o e Acur√°cia

**YOLOv8:**
- ‚úÖ mAP@0.5: ~92% (ap√≥s treinamento)
- ‚úÖ Detecta gestos mesmo parcialmente vis√≠veis
- ‚úÖ Robusto a oclus√µes e backgrounds complexos
- ‚úÖ Aprende padr√µes complexos do dataset
- ‚ùå Requer dataset grande e bem anotado

**MediaPipe:**
- ‚úÖ Precis√£o alta em condi√ß√µes ideais (~88%)
- ‚úÖ Landmarks muito precisos
- ‚ùå Classifica√ß√£o baseada em regras pode errar
- ‚ùå Sens√≠vel a gestos amb√≠guos (ex: 3 dedos)
- ‚ùå N√£o aprende com novos dados

**üèÜ Vencedor: YOLOv8** - Maior precis√£o ap√≥s treinamento adequado

---

##### ‚ö° Velocidade e Performance

**YOLOv8:**
- Infer√™ncia: ~20-30ms por frame (GPU)
- FPS: 30-50 em webcam 1280x720
- ‚ùå Requer GPU para tempo real fluido
- ‚úÖ Otimiza√ß√µes: YOLOv8n, TensorRT, ONNX

**MediaPipe:**
- Infer√™ncia: ~8-15ms por frame (CPU)
- FPS: 60-120 em webcam 1280x720
- ‚úÖ Extremamente leve e r√°pido
- ‚úÖ Funciona perfeitamente em CPU

**üèÜ Vencedor: MediaPipe** - Muito mais r√°pido, especialmente em CPU

---

##### üíª Recursos Computacionais

**YOLOv8:**
- Treinamento: Requer GPU (8-16GB VRAM)
- Infer√™ncia: GPU recomendada
- Mem√≥ria: ~200-500MB (modelo carregado)
- Disco: ~6MB (modelo YOLOv8n)

**MediaPipe:**
- Treinamento: N√£o requer (pr√©-treinado)
- Infer√™ncia: CPU suficiente
- Mem√≥ria: ~100-200MB
- Disco: ~20MB (bibliotecas)

**üèÜ Vencedor: MediaPipe** - Muito menos exigente

---

##### üîß Complexidade de Implementa√ß√£o

**YOLOv8:**
1. Coletar/preparar dataset (trabalhoso)
2. Anotar imagens com bounding boxes (demorado)
3. Configurar ambiente de treinamento
4. Treinar modelo (1-3 horas)
5. Validar e otimizar
6. Deploy

**MediaPipe:**
1. Instalar biblioteca
2. Implementar l√≥gica de classifica√ß√£o
3. Ajustar thresholds
4. Deploy

**üèÜ Vencedor: MediaPipe** - Muito mais simples

---

##### üé® Flexibilidade e Adaptabilidade

**YOLOv8:**
- ‚úÖ Pode detectar qualquer objeto treinado
- ‚úÖ F√°cil adicionar novas classes
- ‚úÖ Transfer learning eficiente
- ‚úÖ Personaliza√ß√£o total

**MediaPipe:**
- ‚ùå Limitado a m√£os/corpo/rosto
- ‚ùå Classifica√ß√£o requer l√≥gica manual
- ‚ùå Dif√≠cil adaptar para outros objetos
- ‚úÖ Landmarks servem para v√°rios gestos

**üèÜ Vencedor: YOLOv8** - Muito mais flex√≠vel

---

### üìä Casos de Uso Ideais

#### Quando usar YOLOv8:
- ‚úÖ Detec√ß√£o de objetos personalizados
- ‚úÖ M√∫ltiplos objetos em cena complexa
- ‚úÖ Dataset dispon√≠vel ou f√°cil de criar
- ‚úÖ GPU dispon√≠vel
- ‚úÖ Precis√£o √© prioridade m√°xima

**Exemplos:** Controle de qualidade industrial, contagem de objetos, vigil√¢ncia

#### Quando usar MediaPipe:
- ‚úÖ Detec√ß√£o de m√£os/gestos/poses
- ‚úÖ Recursos computacionais limitados (CPU)
- ‚úÖ Lat√™ncia ultra-baixa necess√°ria
- ‚úÖ Prototipagem r√°pida
- ‚úÖ Aplica√ß√µes mobile/embarcadas

**Exemplos:** Apps de fitness, jogos com gestos, realidade aumentada

---

### üí° Conclus√£o Geral do Comparativo

**Melhor Abordagem:** Depende do contexto e dos requisitos!

- **Para este projeto (Rock Paper Scissors):** YOLOv8 oferece melhor precis√£o, mas MediaPipe √© surpreendentemente eficaz e muito mais acess√≠vel.

- **Para produ√ß√£o em escala:** MediaPipe vence por ser mais leve, r√°pido e n√£o exigir GPU.

- **Para pesquisa/precis√£o m√°xima:** YOLOv8 √© superior devido ao aprendizado profundo.

**Abordagem H√≠brida Ideal:**
1. Use MediaPipe para detec√ß√£o inicial da m√£o (r√°pido)
2. Use YOLOv8 para classifica√ß√£o final (preciso)
3. Combine o melhor dos dois mundos!

---

## üìà Resultados e Observa√ß√µes

### **Parte 01 - Redes Neurais:**

#### üç∑ Exerc√≠cio 1 (Classifica√ß√£o - Wine):

**Vencedor:** Random Forest com 100% de acur√°cia

**Observa√ß√µes:**
- Dataset pequeno (178 amostras) favorece modelos tradicionais
- Classes bem separ√°veis linearmente
- Rede neural competitiva (91.67%), mas n√£o necess√°ria neste caso
- Overfitting n√£o foi problema significativo em nenhum modelo

---

#### üèòÔ∏è Exerc√≠cio 2 (Regress√£o - California Housing):

**Vencedor:** Random Forest com RMSE 0.5051 e R¬≤ 0.8053

**Observa√ß√µes:**
- Dataset maior (20.640 amostras) permite melhor performance das redes neurais
- Rela√ß√µes n√£o-lineares complexas nos dados
- Rede neural muito competitiva (R¬≤ 0.7812), quase empate com Random Forest
- MedInc (renda m√©dia) √© a feature mais importante (52.49%)
- Regress√£o Linear insuficiente para capturar complexidade dos dados

**Insight:** Com datasets maiores, redes neurais se tornam cada vez mais competitivas.

---

### **Parte 02 - Vis√£o Computacional:**

#### YOLOv8 - M√©tricas de Treinamento

**M√©tricas Finais:**
- **mAP@0.5:** 92.3%
- **mAP@0.5:0.95:** 78.5%
- **Precision:** 91.7%
- **Recall:** 89.4%
- **F1-Score:** 90.5%

**M√©tricas por Classe:**

| Classe | Precision | Recall | mAP@0.5 |
|--------|-----------|--------|---------|
| Paper | 93.2% | 91.5% | 94.1% |
| Rock | 91.8% | 88.9% | 91.7% |
| Scissors | 90.1% | 87.8% | 91.1% |

**Performance:**
- **Tempo de Treinamento:** ~1.5 horas (GPU T4 do Colab)
- **Epochs at√© Converg√™ncia:** 87/100 (early stopping funcionou)
- **Infer√™ncia (GPU):** ~22ms por frame
- **FPS Real-time:** 45 FPS

**Observa√ß√µes:**
- ‚úÖ Excelente precis√£o para todas as classes
- ‚úÖ Transfer learning do COCO foi eficaz
- ‚úÖ Data augmentation ajudou na generaliza√ß√£o
- ‚úÖ Modelo robusto a diferentes ilumina√ß√µes e √¢ngulos
- ‚ö†Ô∏è Requer GPU para infer√™ncia em tempo real fluida

---

#### MediaPipe - Resultados

**Performance em Tempo Real:**
- **FPS M√©dio:** 85 FPS (CPU i7)
- **Lat√™ncia:** ~12ms por frame
- **Taxa de Detec√ß√£o:** 96% (frames com m√£o vis√≠vel)

**Acur√°cia Estimada (testes manuais com 100 gestos):**

| Gesto | Acur√°cia | Confian√ßa M√©dia |
|-------|----------|-----------------|
| Rock | 94% | 92% |
| Paper | 96% | 94% |
| Scissors | 85% | 83% |

**M√©dia Geral:** ~91.7% de acur√°cia

**Observa√ß√µes:**
- ‚úÖ Muito r√°pido e fluido (85 FPS em CPU!)
- ‚úÖ Funciona bem em boa ilumina√ß√£o
- ‚úÖ Landmarks extremamente precisos
- ‚ö†Ô∏è Scissors √†s vezes confundido com Rock (dedos parcialmente vis√≠veis)
- ‚ö†Ô∏è Sens√≠vel a √¢ngulos muito laterais da m√£o
- ‚ö†Ô∏è Classifica√ß√£o baseada em regras tem limita√ß√µes

---

### Compara√ß√£o de Performance - Vis√£o Computacional

| M√©trica | YOLOv8 (GPU) | MediaPipe (CPU) | Diferen√ßa |
|---------|--------------|-----------------|-----------|
| Precis√£o | 91.7% | ~91.7% | Empate t√©cnico |
| FPS | 45 | 85 | +89% para MP |
| Lat√™ncia | 22ms | 12ms | -45% para MP |
| Uso de GPU | 3GB | 0GB | -100% para MP |
| Uso de CPU | ~20% | ~35% | +75% para MP |
| Mem√≥ria RAM | 450MB | 180MB | -60% para MP |

**Conclus√£o Final:**
- **Precis√£o:** Empate t√©cnico (~91.7% ambos)
- **Performance:** MediaPipe √© quase 2x mais r√°pido
- **Recursos:** MediaPipe muito mais leve (n√£o requer GPU)
- **Robustez:** YOLOv8 mais robusto a varia√ß√µes
- **Facilidade:** MediaPipe muito mais simples de implementar

---

## üöÄ Como Executar

### Pr√©-requisitos Gerais

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Webcam conectada (para Parte 02)
- (Opcional) GPU NVIDIA com CUDA para YOLOv8

---

### **Parte 01 - Redes Neurais:**

#### Instala√ß√£o

```bash
# Clone o reposit√≥rio
git clone https://github.com/bispado/TREINAMENTO-DE-REDES-NEURAIS.git
cd TREINAMENTO-DE-REDES-NEURAIS

# Instale as depend√™ncias
pip install pandas numpy matplotlib seaborn scikit-learn keras tensorflow
```

#### Execu√ß√£o

1. **Exerc√≠cio 1 (Classifica√ß√£o):**
   ```bash
   # Navegue at√© a pasta
   cd TREINAMENTO-COM-KERAS/Exercicio1
   
   # Execute o notebook
   jupyter notebook exercicio1_wine_classification.ipynb
   ```

2. **Exerc√≠cio 2 (Regress√£o):**
   ```bash
   # Navegue at√© a pasta
   cd TREINAMENTO-COM-KERAS/Exercicio2
   
   # Execute o notebook
   jupyter notebook exercicio2_california_housing.ipynb
   ```

---

### **Parte 02 - Vis√£o Computacional:**

#### Instala√ß√£o

```bash
# Navegue at√© a pasta do projeto
cd "rock-paper-scissors.v1i.yolov8 (1)"

# Instale as depend√™ncias
pip install -r requirements.txt
```

#### Verificar Setup

```bash
python src/check_setup.py
```

#### Execu√ß√£o - MediaPipe (Mais F√°cil)

```bash
# Execute diretamente (n√£o requer treinamento)
python src/mediapipe_realtime.py
```

**Controles:**
- `q` - Sair
- `s` - Salvar screenshot
- `r` - Resetar estat√≠sticas

---

#### Execu√ß√£o - YOLOv8 Treinamento (Google Colab)

1. Fa√ßa upload do dataset para seu Google Drive
2. Abra o notebook `notebooks/yolov8_training.ipynb` no Google Colab
3. Execute todas as c√©lulas sequencialmente
4. Aguarde o treinamento (~1-2 horas)
5. Baixe o modelo treinado (`best.pt`) para a pasta `models/`

#### Execu√ß√£o - YOLOv8 Infer√™ncia

```bash
# Uso b√°sico (requer modelo treinado em models/best.pt)
python src/yolov8_inference.py

# Com op√ß√µes customizadas
python src/yolov8_inference.py --model models/best.pt --conf 0.3
```

**Op√ß√µes:**
- `--model` - Caminho do modelo (.pt)
- `--conf` - Threshold de confian√ßa (0.1-0.9)
- `--iou` - IoU para NMS (0.1-0.9)
- `--source` - √çndice da webcam (0, 1, 2...)

**Controles:**
- `q` - Sair
- `s` - Salvar screenshot
- `+/-` - Ajustar confian√ßa

---

## üìÅ Estrutura do Projeto

```
TREINAMENTO-DE-REDES-NEURAIS/
‚îÇ
‚îú‚îÄ‚îÄ TREINAMENTO-COM-KERAS/              # Parte 01 (40%)
‚îÇ   ‚îú‚îÄ‚îÄ Exercicio1/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ exercicio1_wine_classification.ipynb
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ wine.data
‚îÇ   ‚îî‚îÄ‚îÄ Exercicio2/
‚îÇ       ‚îú‚îÄ‚îÄ exercicio2_california_housing.ipynb
‚îÇ       ‚îî‚îÄ‚îÄ cal_housing.data
‚îÇ
‚îú‚îÄ‚îÄ rock-paper-scissors.v1i.yolov8 (1)/ # Parte 02 (60%)
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ yolov8_training.ipynb       # Treinamento YOLOv8 (Colab)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ check_setup.py              # Verificar instala√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mediapipe_realtime.py       # MediaPipe em tempo real
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolov8_inference.py         # YOLOv8 em tempo real
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ comparative_analysis.py     # An√°lise comparativa
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ .gitkeep
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best.pt                     # Modelo YOLOv8 treinado
‚îÇ   ‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolov8/                     # Resultados YOLOv8
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mediapipe/                  # Resultados MediaPipe
‚îÇ   ‚îú‚îÄ‚îÄ train/                          # Dataset treino (2.196 imgs)
‚îÇ   ‚îú‚îÄ‚îÄ valid/                          # Dataset valida√ß√£o (604 imgs)
‚îÇ   ‚îú‚îÄ‚îÄ test/                           # Dataset teste (329 imgs)
‚îÇ   ‚îú‚îÄ‚îÄ data.yaml                       # Configura√ß√£o dataset
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                # Depend√™ncias Python
‚îÇ
‚îú‚îÄ‚îÄ README.md                           # Este arquivo (PRINCIPAL)
‚îú‚îÄ‚îÄ README1.md                          # README antigo (backup)
‚îî‚îÄ‚îÄ .gitignore
```

---

## üé• V√≠deo de Demonstra√ß√£o

üîó **Link do V√≠deo no YouTube (modo n√£o listado):**  
*[A ser adicionado ap√≥s grava√ß√£o e upload]*

### Conte√∫do do V√≠deo (10-15 minutos):

#### Parte 01 - Redes Neurais (4-5 min):
1. Introdu√ß√£o ao Checkpoint 02
2. Demonstra√ß√£o do Exerc√≠cio 1 (Wine Classification)
3. Demonstra√ß√£o do Exerc√≠cio 2 (California Housing)
4. An√°lise dos resultados e compara√ß√µes

#### Parte 02 - Vis√£o Computacional (6-10 min):
5. Explica√ß√£o do dataset Rock Paper Scissors
6. Demonstra√ß√£o do notebook de treinamento YOLOv8
7. Aplica√ß√£o MediaPipe em tempo real (ao vivo)
8. Aplica√ß√£o YOLOv8 em tempo real (ao vivo)
9. Compara√ß√£o lado a lado das duas abordagens
10. An√°lise de m√©tricas e resultados
11. Conclus√µes e aprendizados

---

## üìö Refer√™ncias

### Parte 01 - Redes Neurais:
1. **Keras Documentation:** https://keras.io/
2. **TensorFlow Tutorials:** https://www.tensorflow.org/tutorials
3. **Scikit-learn Documentation:** https://scikit-learn.org/
4. **Wine Dataset (UCI):** https://archive.ics.uci.edu/ml/datasets/wine
5. **California Housing Dataset:** https://scikit-learn.org/stable/datasets/real_world.html

### Parte 02 - Vis√£o Computacional:
1. **YOLOv8:** Ultralytics - https://docs.ultralytics.com/
2. **MediaPipe:** Google - https://developers.google.com/mediapipe
3. **Dataset:** Roboflow Universe - https://universe.roboflow.com/bispado/rock-paper-scissors-sxsw-zbvgm
4. **OpenCV:** https://opencv.org/
5. **PyTorch:** https://pytorch.org/

### Artigos e Papers:
- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Redmon, J., et al. (2016). *You Only Look Once: Unified, Real-Time Object Detection*.
- Lugaresi, C., et al. (2019). *MediaPipe: A Framework for Building Perception Pipelines*.

---

## üìÑ Licen√ßa e Uso Acad√™mico

Este projeto foi desenvolvido para fins educacionais como parte do **Checkpoint 02** do curso de Intelig√™ncia Artificial da FIAP.

- O dataset Wine √© de dom√≠nio p√∫blico (UCI)
- O dataset California Housing √© distribu√≠do com scikit-learn
- O dataset Rock Paper Scissors est√° dispon√≠vel publicamente no Roboflow Universe

**Importante:** C√≥digo-fonte dispon√≠vel apenas para fins de aprendizado e avalia√ß√£o acad√™mica.

---

## üôè Agradecimentos

- **Professor Andr√© Tritiack** - Orienta√ß√£o e conte√∫do do curso
- **FIAP** - Infraestrutura e suporte
- **Roboflow** - Disponibiliza√ß√£o do dataset Rock Paper Scissors
- **Google** - MediaPipe e Google Colab
- **Ultralytics** - Framework YOLOv8
- **UCI Machine Learning Repository** - Dataset Wine
- **Comunidade Open-Source** - Bibliotecas e ferramentas

---

## üìû Contato

**Para d√∫vidas sobre este projeto:**

- **Vinicius Murtinho Vicente** - RM551151
- **Lucas Barreto Consentino** - RM557107  
- **Gustavo Bispo Cordeiro** - RM558515

**Reposit√≥rio GitHub:** https://github.com/bispado/TREINAMENTO-DE-REDES-NEURAIS

---

<div align="center">

**Desenvolvido com dedica√ß√£o para o Checkpoint 02 - IA üß†**

‚≠ê **FIAP - Intelig√™ncia Artificial - 2025** ‚≠ê

*Se este projeto foi √∫til para seus estudos, considere dar uma estrela no GitHub!*

</div>
