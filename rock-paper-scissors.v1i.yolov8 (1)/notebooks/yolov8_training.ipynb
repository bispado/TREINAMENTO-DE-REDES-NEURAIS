{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Treinamento YOLOv8 - Rock Paper Scissors\n",
        "\n",
        "Este notebook treina um modelo YOLOv8 para detectar gestos de Pedra, Papel e Tesoura.\n",
        "\n",
        "**Autor:** Projeto de Visão Computacional  \n",
        "**Dataset:** Rock Paper Scissors (Roboflow)  \n",
        "**Modelo:** YOLOv8n (Nano) - otimizado para velocidade e precisão\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup e Instalação de Dependências\n",
        "\n",
        "Instalamos o Ultralytics que contém a implementação do YOLOv8.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar Ultralytics YOLOv8\n",
        "!pip install ultralytics -q\n",
        "\n",
        "# Verificar instalação\n",
        "import ultralytics\n",
        "print(f\"Ultralytics versão: {ultralytics.__version__}\")\n",
        "\n",
        "# Verificar GPU disponível\n",
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Importação de Bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "print(f\"PyTorch versão: {torch.__version__}\")\n",
        "print(f\"CUDA disponível: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Montar Google Drive e Preparar Dataset\n",
        "\n",
        "**Instruções:**\n",
        "1. Faça upload da pasta do dataset para seu Google Drive\n",
        "2. A estrutura deve ser:\n",
        "   ```\n",
        "   /content/drive/MyDrive/rock-paper-scissors/\n",
        "   ├── train/\n",
        "   ├── valid/\n",
        "   ├── test/\n",
        "   └── data.yaml\n",
        "   ```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir caminhos\n",
        "DATASET_PATH = '/content/drive/MyDrive/rock-paper-scissors'\n",
        "WORK_DIR = '/content/yolov8_rps'\n",
        "\n",
        "# Criar diretório de trabalho\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.chdir(WORK_DIR)\n",
        "\n",
        "print(f\"Diretório de trabalho: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Verificar e Ajustar data.yaml\n",
        "\n",
        "O arquivo `data.yaml` contém as configurações do dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ler o data.yaml original\n",
        "with open(f'{DATASET_PATH}/data.yaml', 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Configuração original do dataset:\")\n",
        "print(data_config)\n",
        "\n",
        "# Ajustar caminhos para ambiente Colab\n",
        "data_config['train'] = f'{DATASET_PATH}/train/images'\n",
        "data_config['val'] = f'{DATASET_PATH}/valid/images'\n",
        "data_config['test'] = f'{DATASET_PATH}/test/images'\n",
        "\n",
        "# Salvar nova configuração\n",
        "new_yaml_path = f'{WORK_DIR}/data.yaml'\n",
        "with open(new_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f)\n",
        "\n",
        "print(\"\\nNova configuração ajustada:\")\n",
        "print(data_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Análise Exploratória do Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contar imagens em cada conjunto\n",
        "train_images = len(os.listdir(f'{DATASET_PATH}/train/images'))\n",
        "val_images = len(os.listdir(f'{DATASET_PATH}/valid/images'))\n",
        "test_images = len(os.listdir(f'{DATASET_PATH}/test/images'))\n",
        "\n",
        "print(f\"Imagens de Treinamento: {train_images}\")\n",
        "print(f\"Imagens de Validação: {val_images}\")\n",
        "print(f\"Imagens de Teste: {test_images}\")\n",
        "print(f\"Total: {train_images + val_images + test_images}\")\n",
        "\n",
        "# Distribuição\n",
        "print(f\"\\nDistribuição:\")\n",
        "print(f\"Train: {train_images/(train_images+val_images+test_images)*100:.1f}%\")\n",
        "print(f\"Val: {val_images/(train_images+val_images+test_images)*100:.1f}%\")\n",
        "print(f\"Test: {test_images/(train_images+val_images+test_images)*100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar algumas imagens do dataset\n",
        "import random\n",
        "\n",
        "train_img_dir = f'{DATASET_PATH}/train/images'\n",
        "sample_images = random.sample(os.listdir(train_img_dir), min(6, len(os.listdir(train_img_dir))))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, img_name in enumerate(sample_images):\n",
        "    img_path = os.path.join(train_img_dir, img_name)\n",
        "    img = PILImage.open(img_path)\n",
        "    axes[idx].imshow(img)\n",
        "    axes[idx].set_title(img_name)\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Configuração de Hiperparâmetros\n",
        "\n",
        "### Justificativa das Escolhas:\n",
        "\n",
        "- **Modelo YOLOv8n**: Versão Nano escolhida por oferecer excelente equilíbrio entre velocidade e precisão, ideal para aplicações em tempo real.\n",
        "- **Epochs: 100**: Número suficiente para convergência sem overfitting, com early stopping.\n",
        "- **Batch Size: 16**: Balanceado para GPU do Colab (T4/P100).\n",
        "- **Image Size: 640**: Tamanho padrão do YOLO, bom para detectar objetos de tamanhos variados.\n",
        "- **Learning Rate: 0.01**: Taxa de aprendizado inicial do YOLO, com scheduler automático.\n",
        "- **Patience: 50**: Early stopping após 50 epochs sem melhora no mAP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hiperparâmetros de treinamento\n",
        "HYPERPARAMETERS = {\n",
        "    'model': 'yolov8n.pt',\n",
        "    'data': new_yaml_path,\n",
        "    'epochs': 100,\n",
        "    'batch': 16,\n",
        "    'imgsz': 640,\n",
        "    'lr0': 0.01,\n",
        "    'lrf': 0.01,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "    'warmup_epochs': 3.0,\n",
        "    'patience': 50,\n",
        "    'device': 0,\n",
        "    'workers': 8,\n",
        "    'project': 'runs/detect',\n",
        "    'name': 'rps_yolov8n',\n",
        "    'exist_ok': True,\n",
        "    'pretrained': True,\n",
        "    'optimizer': 'auto',\n",
        "    'verbose': True,\n",
        "    'seed': 42,\n",
        "}\n",
        "\n",
        "print(\"Hiperparâmetros configurados:\")\n",
        "for key, value in HYPERPARAMETERS.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Treinamento do Modelo\n",
        "\n",
        "⚠️ **Atenção**: Este processo pode levar de 30 minutos a 2 horas dependendo da GPU disponível.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar modelo pré-treinado\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Treinar modelo\n",
        "results = model.train(\n",
        "    data=HYPERPARAMETERS['data'],\n",
        "    epochs=HYPERPARAMETERS['epochs'],\n",
        "    batch=HYPERPARAMETERS['batch'],\n",
        "    imgsz=HYPERPARAMETERS['imgsz'],\n",
        "    lr0=HYPERPARAMETERS['lr0'],\n",
        "    lrf=HYPERPARAMETERS['lrf'],\n",
        "    momentum=HYPERPARAMETERS['momentum'],\n",
        "    weight_decay=HYPERPARAMETERS['weight_decay'],\n",
        "    warmup_epochs=HYPERPARAMETERS['warmup_epochs'],\n",
        "    patience=HYPERPARAMETERS['patience'],\n",
        "    device=HYPERPARAMETERS['device'],\n",
        "    workers=HYPERPARAMETERS['workers'],\n",
        "    project=HYPERPARAMETERS['project'],\n",
        "    name=HYPERPARAMETERS['name'],\n",
        "    exist_ok=HYPERPARAMETERS['exist_ok'],\n",
        "    pretrained=HYPERPARAMETERS['pretrained'],\n",
        "    optimizer=HYPERPARAMETERS['optimizer'],\n",
        "    verbose=HYPERPARAMETERS['verbose'],\n",
        "    seed=HYPERPARAMETERS['seed'],\n",
        ")\n",
        "\n",
        "print(\"\\n✅ Treinamento concluído!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualização dos Resultados de Treinamento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Caminho para os resultados\n",
        "results_path = Path('runs/detect/rps_yolov8n')\n",
        "\n",
        "# Visualizar curvas de treinamento\n",
        "results_img = results_path / 'results.png'\n",
        "if results_img.exists():\n",
        "    display(Image(filename=str(results_img)))\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion_matrix_img = results_path / 'confusion_matrix.png'\n",
        "if confusion_matrix_img.exists():\n",
        "    print(\"Matriz de Confusão:\")\n",
        "    display(Image(filename=str(confusion_matrix_img)))\n",
        "\n",
        "# F1 Curve e PR Curve\n",
        "f1_curve_img = results_path / 'F1_curve.png'\n",
        "if f1_curve_img.exists():\n",
        "    display(Image(filename=str(f1_curve_img)))\n",
        "\n",
        "pr_curve_img = results_path / 'PR_curve.png'\n",
        "if pr_curve_img.exists():\n",
        "    display(Image(filename=str(pr_curve_img)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Validação no Conjunto de Teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar melhor modelo treinado\n",
        "best_model = YOLO(results_path / 'weights' / 'best.pt')\n",
        "\n",
        "# Validar no conjunto de teste\n",
        "metrics = best_model.val(data=new_yaml_path, split='test')\n",
        "\n",
        "print(\"\\n📊 Métricas no Conjunto de Teste:\")\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
        "print(f\"Recall: {metrics.box.mr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Inferência em Imagens de Teste\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Realizar predições em algumas imagens de teste\n",
        "test_img_dir = f'{DATASET_PATH}/test/images'\n",
        "sample_test_images = random.sample(os.listdir(test_img_dir), min(6, len(os.listdir(test_img_dir))))\n",
        "\n",
        "for img_name in sample_test_images:\n",
        "    img_path = os.path.join(test_img_dir, img_name)\n",
        "    \n",
        "    # Fazer predição\n",
        "    results = best_model.predict(source=img_path, conf=0.25, save=False)\n",
        "    \n",
        "    # Visualizar resultado\n",
        "    result_img = results[0].plot()\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(result_img[..., ::-1])\n",
        "    plt.title(f\"Predição: {img_name}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "    # Mostrar detecções\n",
        "    if len(results[0].boxes) > 0:\n",
        "        print(f\"\\nDetecções em {img_name}:\")\n",
        "        for box in results[0].boxes:\n",
        "            cls = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            class_name = data_config['names'][cls]\n",
        "            print(f\"  - {class_name}: {conf:.2%}\")\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Análise de Performance e Exportação\n",
        "\n",
        "Vamos medir a velocidade de inferência e exportar o modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Testar velocidade de inferência\n",
        "test_images_list = [os.path.join(test_img_dir, img) for img in os.listdir(test_img_dir)[:50]]\n",
        "\n",
        "# Warmup\n",
        "for _ in range(10):\n",
        "    best_model.predict(test_images_list[0], verbose=False)\n",
        "\n",
        "# Medir tempo\n",
        "start_time = time.time()\n",
        "for img_path in test_images_list:\n",
        "    results = best_model.predict(img_path, verbose=False)\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "avg_time = total_time / len(test_images_list)\n",
        "fps = 1 / avg_time\n",
        "\n",
        "print(\"\\n⚡ Performance de Inferência:\")\n",
        "print(f\"Tempo total para {len(test_images_list)} imagens: {total_time:.2f}s\")\n",
        "print(f\"Tempo médio por imagem: {avg_time*1000:.2f}ms\")\n",
        "print(f\"FPS estimado: {fps:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Copiar modelo para o Drive\n",
        "best_pt_path = results_path / 'weights' / 'best.pt'\n",
        "drive_model_path = '/content/drive/MyDrive/rock-paper-scissors/best_yolov8n.pt'\n",
        "shutil.copy(best_pt_path, drive_model_path)\n",
        "print(f\"Modelo .pt salvo no Drive: {drive_model_path}\")\n",
        "\n",
        "# Copiar pasta de resultados completa\n",
        "drive_results_path = '/content/drive/MyDrive/rock-paper-scissors/results_yolov8n'\n",
        "if os.path.exists(drive_results_path):\n",
        "    shutil.rmtree(drive_results_path)\n",
        "shutil.copytree(results_path, drive_results_path)\n",
        "print(f\"Resultados salvos no Drive: {drive_results_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Conclusões\n",
        "\n",
        "### Pontos Fortes do YOLOv8:\n",
        "- ✅ Alta precisão na detecção de múltiplas mãos simultaneamente\n",
        "- ✅ Robusto a diferentes ângulos e condições de iluminação\n",
        "- ✅ Detecta objetos com bounding boxes precisos\n",
        "- ✅ Pré-treinado em COCO facilita transfer learning\n",
        "- ✅ Excelente documentação e comunidade ativa\n",
        "\n",
        "### Limitações:\n",
        "- ❌ Requer dataset rotulado com bounding boxes\n",
        "- ❌ Treinamento demora e requer GPU potente\n",
        "- ❌ Modelos maiores podem ser lentos em tempo real\n",
        "- ❌ Necessita fine-tuning para cada caso de uso\n",
        "\n",
        "### Próximos Passos:\n",
        "1. Usar o modelo treinado no script de inferência em tempo real\n",
        "2. Comparar com MediaPipe para análise comparativa\n",
        "3. Otimizar para produção se necessário\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
